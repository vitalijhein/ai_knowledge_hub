{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(video_id_or_url):\n",
    "    if len(video_id_or_url) > 11:\n",
    "        return video_id_or_url[-11:]\n",
    "    else:\n",
    "        return video_id_or_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_transcript(video_url_or_id):\n",
    "    try:\n",
    "        video_id = extract_video_id(video_url_or_id)\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if you want to see a real life example of how a marketing agency productized their service look no further in this episode I'm interviewing Spencer Powell of builderfunnel.com they are a marketing agency for custom home builders and remodelers in this episode he's actually going to share how he followed a lot of what we preach around having three income streams done for you a done with you in a DIY to transform his custom Services Agency into a very specialized productized delivery structure for his clients and how it's working extremely well so let's hop over into the interview alright guys so I'm joined here with Spencer Powell from Builder funnel and I'm super stoked to chat with him today and kind of have him share his story for the kickoff like Spencer is not a client we have not worked with him but he reached out after watching one of our YouTube videos around how agencies should have three income streams and we started chatting and he was sharing about everything he was doing and I was like Hey like let's have you deconstruct your journey in moving from one offer to multiple income streams so Spencer dude first thanks for reaching you know thanks for you know checking out the content and stoked to have you cool yeah I'm excited to be here and yeah you're doing awesome stuff I feel like agency space can be really challenging but then if you get a couple things clicked in not that it's not hard anymore but it's easier yeah easier that way so give a quick high level like Builder funnel who do you serve and what do you guys do as it stands right now cool yeah so we're pretty Niche focused we serve remodeling companies we kind of fall under the design build umbrella so design Builder modelers and then some custom Builders but it's all interior stuff so not the generally kitchens bass additions whole home not a lot of like just windows and siding guys and we help them generate more leads so my first question is when I see you know a lot of what we talk about on our YouTube channel and with our clients is that in order to kind of go to this multi-income stream model that like where there's done for you done with you DIY type offerings that there's a kind of a precursor of really needing to specialize eyes and so you obviously are specialized in the who you serve that's a very specific market so the first question really is where did that market selection come from like do you have a background in this like how did you end up with them yeah I'll give you the short long family history so basically I come from four generations of Home Builders out in the Seattle market and so at the time that I was getting out of college I was like I want to start my own thing started like a social media business because that was like when Facebook business Pages were new and stuff like that but really I started working with my uncle's company at the time so that that was the fourth generation they were doing a lot of SPEC Building and the Great Recession hit and they were doing no SPEC Building and so they pivoted to Remodeling and Custom Homes and we I clipped in and just started doing like blogging and SEO and social media and trying to just figure it out it was like 2010 ish and uh we took the remodeling division from 2 million to 10 million over about four years and kind of figuring out the online space and so they were like well I think we can go help other people do this and we dabbled for a little bit we took took on other clients from other Industries and after a while I was just like this is so freaking hard you have to figure out every industry every time for every client like everything is custom and you really needed like somebody that could be a marketing strategist and a good listener and like really dig in and understand all the pains to actually do a good job for that client and you couldn't really systematize a lot so we took that leap eventually and we created the Builder funnel brand said we're just going to serve this audience but it really at the being it was builders remodelers and contractors which is still a massive industry and over the last 10 years I'd say we just like chipped away and narrowed it within even that bucket of like residential construction I love that and I think you know takeaway for those watching or listening is just like I think many people would lump the like you said the Builder the remodeler and what was the third one contractors so like especially in there like oh that's that's Niche enough and it's like you could actually Niche even further into like residential Remodel and that's kind of where a lot of the unlock you know seemed to happen so that's super cool because again one thing that I harp on a lot and we get a lot of folks that kind of inquire about joining our programs and they had spent two three five plus years of doing the I've worked with all of these different types of clients but they didn't have any family history or any just breakout success story from any one of those types of clients that really allowed them to simply be like oh yeah like I gotta go to you know remodelers some of them don't even have the experience to like go and have enough reps in any one Niche to like you know to pick and so I think that's kind of why I started with that question because I think a lot of people get ahead of themselves they see oh my God yeah multiple income streams I'm stuck in fulfillment and it's like well yeah you're stuck in fulfillment kind of like you alluded to because every client's different and then they all need different systems so that's kind of a common challenge so that's good you have that experience I would throw something else in there too like one thing it was really tough to make that decision I'm not gonna I was sitting there and thinking like I know I should do this but it still feels like way too challenging and I would encourage people listening to just sing think through what you want to Target like where you've had success those and then just pick because everything got easier like marketing is easier because now you're only focused on attracting them sales is easier because you know where the pain points are you know the problems you actually solve and you actually do solve them because that's all you do and you get this depth of experience that then positions you against other agencies so like they're not just going to go with the local agency anymore because you're the specialist and so I will say it was very difficult even though logically you talk through all those points it's like yeah that makes sense but it's emotionally it was tough to do because you're like I'm turning away everything else but yeah I mean can you go a little bit deeper on that like I know exactly what you're feeling because I had done the same thing but like a lot of people I think will be nodding their head right now and they'll agree with you but they still won't kind of make it happen so like can you talk a little bit about like why was it so scary and like kind of the mix between the logic and the emotion like were there any things that you actually did to finally make that decision yeah I think it's scary because it feels like you won't have have enough opportunity because up to this point you've attracted opportunity from several Industries and so now you're saying well I'm picking this one industry that maybe I only have like one or two clients in and now I'm gonna say no and so all of your inquiries and probably all your marketing and sales efforts at this point has just been like sporadic and all over the place and so it does require you to kind of focus and what I would say is like you don't have to just drop all those clients that are not in that industry right away but you just start focusing all of your marketing efforts one of the things we did was we actually just created a side brand which became the main brand long story we were wrapped in with my dad's Direct Mail company at the time we started a digital division so it was like TMR direct was the old school company name and we were just serving everyone we created Builder funnel as like a signal saying like yep we're actually committing to this and that helped me too because I was like okay like our name is around this it's not like we're trying to serve other people and so I think that helped a ton and then we just everything we did for marketing all of our blogs our videos our podcasts it was all speaking directly to that audience you go on LinkedIn you you're only looking for those companies you know so like all these big Pockets online get a lot smaller and you go oh my audience is here and it's here and it's here oh we'll go to this one trade show and now you know you've got a clear path and you start picking up momentum I love it and so you made the kind of decision to focus on remodelers and what was the offer when you first started you talked to like the evolution of the offer yeah it was pretty ugly early I mean I would say there wasn't like it wasn't a strong offer it was still in that like 2011 12 13 and especially when you think about the context of our industry being remodelers they're typically way behind on Tech on websites on digital marketing and so we kind of were coming and we had something new and different to them and it was we're gonna make your website generate leads and so we followed the standard like inbound methodology is like we're doing these things to drive traffic it's blogging it's SEO it's social it's paid we're doing these things increase leads right there's top of the funnel and bottom of funnel so we're gonna create like your remodeling cost you know document you know guide ebook you know a process checklist starting to capture type of funnel leads now we're going to build a nurturing sequence to like stay in front of these people hey if they're doing a 500 000 remodel they're probably going to think about it for a while so we need to have like an email program and so we just kind of had like activities that filled the funnel like all the way through and we just charge like a setup fee that would take a couple months and then go into a retainer but it was like I had to diagnose on every sales call kind of like where they were look at their analytics and try to build like this customized retainer package for every single client and so finding somebody else that could sell was virtually impossible because they had to know remodeling they had to know marketing really well digital market and then they also had to know how to sell and find you at like person so I was always stuck in the sales seat and then you get pulled into operations when you're small because you're still doing some of the stuff as you build out your team and so the offer really was just this is our full I'm gonna do all this stuff you know we're gonna do this stuff and you know and it was like they hadn't really done it before so it was going from like zero to that so I'm curious because I know that a lot of of agencies that kind of would model that same kind of flow as like hey we do you know an audit we kind of give you a custom proposal and you know the first few months we're setting up some stuff and then we're running managing campaigns was it so successful that you weren't charging enough and that's where you realize things were starting to break or were clients not staying because it was so much and they were like well we're not seeing any results it's taking too long to get all this stuff going and like too chaotic or was it something completely different yeah it's a good question I mean the one thing that we did well from the start is we always put people on retainer and we all needed 12-month contracts so we did get people thinking longer term from the start I would say our problem shaded more towards not charging enough and we'd keep clients like we had a pretty good you know lifetime value they stayed for a couple years you know something like that but yeah we kept having to like figure out how to raise our rates and you know you get pushback and you'd have Legacy clients and then you try to bring people on a new rate but then you're like but we also just need the business so we'll just you know sell it at our old rate this time time because I think we can do it and so we probably over delivered for a long long time we probably still do in some areas you know yeah yeah got it okay cool and so then like what was the straw that broke the candles back where you're like all right something's got to change here this is not sustainable yeah honestly we've made it down that path for about 10 years yeah it wasn't until very recently yeah I think it's been maybe 18 or 20 months or something and I was looking at the trajectory because we were starting to pick up steam and I think part of that was like we had made the shift focus on the vertical really invested in content Marketing in our own efforts and we were starting to build like we had a podcast YouTube channel you know pretty good email list good blog and so we're generating some inbound activity but I could kind of see this path where I was like well I'm the only one selling still and then as you get bigger your churn rate even if it's pretty good like our retention rate is 80 70 raw and then 80 what we can control like if somebody goes out of business we count that as like raw retention rate but even at that like if you're doing you know one and a half million a year and you turn thirty percent and then you kind of scale that out and you're like well if we get to two and a half or three and then we churn I could kind of see the writing on the wall whereas like eventually we'll Flatline like I'll sell whatever our churn rate is and then we'll just kind of hang out there and so I was like well we need to figure out how somebody else can sell and so I've been like grinding on that for a year or something just like trying to figure out how are we going to do this and then really the idea of like productizing I think came onto my scene follow a lot of your stuff and then bumped into Alex hermosi's book 100 million dollar offers and like it just kind of like started clicking I was like you know what yeah we need to like create a killer offer I was like I feel like we have a lot of the components it's just not packaged that way and it's definitely not sold that way it's not marketed that way and so I read the book and I think I just sat down with my marketing director my President we just like busted through four or six weeks like figured it out cranked it out like we're like okay we're going to this we do a remodeling conference every year in the fall where we have a booth and that's like our only show that we do at booth and you know and we're like we gotta launch it there so we like did the whole thing and then that fall in Q4 we sold our first three Blueprints and we originally thought we would sell it at like 30 grand and then we would be like we'll do 20 grand as like discount pricing or whatever for since we're just launching it and now that's just become our standard price so I probably have already like you know cheated myself there by saying like anytime you discount like in your head now that's kind of your price for your own thing but I think it's worked out well kind of where we have it priced but that is like a standard package and process and it mirrors our clients so we're like design build for marketing like the design is the strategy the research and the plan just like for you you don't just run into a kitchen to start ripping out walls like you work with a client to design the kitchen scope it out figure out the budget and so it was a long time before we figured it out and then yeah we sold 24 of them last year but like 12 in Q4 and now like we're on Pace it's gonna be a good year so and so can you explain to folks what the blueprint exactly is you mentioned it's 20K and I know that you know you shared that there's kind of like multiple variations of how you can fundamentally move people through that blueprint so what is the blueprint what are you involved with at the high tier yeah so the high tier for us is the totally done for you we start with the blueprint this is kind of what it ends up looking like you know a finished product it's like 150 pages of research audits of their site you know looking at competitive analysis their competitor sites look at their current traffic lead flow like we do zip code analysis too because they want to Target like certain neighborhoods that are certain income ranges look at household value really granular stuff and stuff that's you know relevant to them as remodelers it takes about four or five weeks and then they can either take the blueprint and just self-implement it so we pair that with all of our training videos all of our Sops that we've built up over the years like if they just want to hire a marketing intern off the street like we tell them they could do a pretty good job with like the blueprint plus the training and then or they can have a self-implement or I mean Implement with us and so that turns into the like hey we'll implement the plan and that's going to be 3 500 to you know Seven Grand a month somewhere in that range just depending on what was in the plan and what their goals are and all those types of things so full service is blueprint plus Implement done with you as blueprint plus we'll give you the tools and you go do it figure eight hours a week to do it and then we do have some DIY that we can get into if you want to with the done with you so the 20K blueprint they get all of the plan all the intern also piece and training videos is there any layer of support and interaction from your team so they get access to some of our like DIY stuff is just like bundled in as bonuses so we have an online community called remodelers growth community that has all of our training videos but they can like ask questions in there our whole team's in there answering questions like Fielding support and stuff like that and then we have formal like a six-month Consulting check-in like zoom out how are you doing on the plan are you actually implementing do we need to make any changes and then we have a 10 month one which is like as they're wrapping up but then working to sign them on for year two blueprint so the 20K gives them that year correct and and you're checking in with them sounds like there's some group elements some on-demand stuff and you're having like a one-on-one touch point at least that's six months to see how things are going do they pay another 20K to go into the next year they do you know let's start down and you done with you yeah I'm done with you so basically it's like a it's able to lose access they would lose access to the 20K all the training and stuff going into year two correct got it and does your Market typically pay in full or are you kind of collecting that over monthly payments it's either pay in full or three payments of seven okay cool and so explain then the DIY so the DIY we launched a online community and our theory was like if we have a community where we're bringing in other thought leaders aside from ourselves on the marketing side but sales operations Finance like other areas of their business doing webinars having them you know contribute content answering questions participating maybe we can build this moat you know around our audience and then we'll get people to ascend you know over time so it's a very long-term play like hey we'll just start building this community we thought we were like got all in on the premium pricing with the blueprints we're like we'll price this premium like a couple hundred bucks a month and we realized like we weren't getting much so that's 49 bucks a month we're actually considering making it free but anyway that's where it stands today is 49 and then we have a done for you social media program which is 199 a month and it's basically templates reels like everything pre-built content that they could share on social media across several platforms but it's all pre-built in in canvas so they can just like drag and drop their own photos tweak the text a little bit like all the reels are synced to the music so they just have to like it's basically a huge Time Saver for them but it's in that like you just subscribe every month you get access to a whole month of content it's like enough to post three to five times a week and then you can either post as is or swap out your own stuff so the DIYs you know couple hundred 300 bucks depending on if you're part of both of those um but if you're if you do the blueprint you just get one your access to both of those at no extra charge got it and so talk to me about like um well first I'll kind of pull back like one of the things that I love about this and that I think some people approach not correctly at least or not in a wise way is like you've stacked all of these things on top of each other it's not like we've seen some people like okay my done for you is we're doing this whole blueprint and the done with you is like a fraction of it and it's like it's still the same outcome fundamentally it's just like the vehicle and the level of support to get to that outcome looks different so I like that I like how it's kind of like stacked on that there are some examples of we have clients where like they're done with you would be like they would actually sell the blueprint as they're done with you and then that would be like handheld like kind of there'd be a lot of like hand holding through that and then it'd be like all right well we can coach you for another year with support and that would be kind of like a continuity of the done with you you kind of weave all that into a year which I actually kind of like talk about like the difference in if there is any like in your side of your sales process you mentioned since you've been doing it well I don't know if you're doing anymore but is there different types of clients like are you like oh they're at a certain level I should go in with done for you or yeah the other levels open your addressable Market yeah it's a great question yeah usually all the discovery calls I mean are trying to figure out like where they are what their goals are what their needs are I mean it's very consultative approach you're trying to diagnose you know and see if we can solve and so through that process I usually still lay out all the options so they can kind of see like there's one two or three you're in these buckets at these price points but almost always you can tell like they're either for sure in the like I just want you to do everything I don't care or they're bouncing between the two because they're like oh I have an office manager or I have a designer that has some time like I might be able to have them you know Implement and they're debating and then usually that's like they're debating between those but people that are like the 20K is too much then we kind of just focus on the DIY it's like hey I'll set you up with a couple of free trials like jump into the programs and that's definitely not a heavy focus of ours it's top two tiers but we do know that that bottom tier gets people into our world and we do have people Ascend it's happened and I'm sure it will continue to but yeah it's really just I don't have like when I go into those calls and uh yeah we're in the process of pulling me out of those calls and so that'll be a big Focus this year but I'm not going in like I really want to sell X I'm just going in trying to learn and see where there's a fit like there's probably a fit out of those three options and so what I noticed really was before we were selling the retainer packages so it'd be 3 4 five grand a month or whatever and people would just sign on for that so it's basically full service is what we had but what this did and so that was like remodelers doing two to ten million or something like that but the blueprint offering basically unlocked sub 2 million because people are like I can't afford the full service but I would love to know exactly what to do and I got somebody that can spend a little bit of time on this and it unlocked the higher end like the 20 million dollar companies that are like they have two marketing people on staff but they're like we're hitting this wall like we need some outside expertise we've got the time and the bandwidth to do the stuff we just need you to tell us what to do and when and what order so that's been the most interesting I think for me is noticing it basically took our Market from like this to like adding on those extensions I love that you said that uh it's like my favorite thing about adding on this kind of like done with you tier in maybe this case by case but like I'm like literally flashing conversations with clients and Prospects through my head right now of like well one once they know about the done for you if they can't afford it they're not going to want the done with you because you're presenting them all three options right it's like they might be that sub 2 million and it makes no sense for them to invest into the three and a half to seven k a month fee like they just can't pull it off but they need the outcome but now they feel like it's not as good enough of an outcome if they have to do it like are you finding that there's still some people that like maybe they don't have that internal person or they're like oh no I'm just gonna go find someone cheaper to do this for me like do you run into that a lot it still happens yeah and I would say that's part of sales right like yeah not everyone's going to close right and that's okay but I will say like the close rate is stronger I mean three options is better than one option because three options are yours and one option is not yours right saying no but the offer and the positioning and the packaging of it is so much stronger you know and so and people being able to look at it it's super easy it's like you always start with the blueprint because that's how you get the best outcome it just depends do you want us spending the time or do you want to spend the time after to build either we build it or you build it and so I think it's drawn more people into saying like yeah I'll do the blueprint and I'll figure out how to do the time part if they couldn't afford the full service and so I think we've picked out more clients and been able to help more people whereas before it just would have been like sorry I can't afford it and it's like well all right like yeah you're at a million like I I get it I wouldn't be able to spend that either if that was my remodeling business all right yeah I think it's just unlocked further conversations with more people because they have options and if they believe in what you're doing and believe you can get the outcome if you can show all the case studies and everything then they want to work with you and so you're just sliding them where they're ready you know yeah we've got a guy that listened to our podcast for two years and he's like I joined some of your like entry level stuff you didn't know his DIY but he joined some of that stuff and he's like I knew I couldn't afford the higher end stuff but he just kept building his business and then he showed up last summer we talked for 45 minutes and needed the blueprint in full service and we're rolling you know and so yeah I think think you have to be okay with playing the long game with some people and just meeting them where they actually are and because literally if they're actually there they can't do whatever the high-end thing is I want to kind of go back to the focusing on the remodeler piece because you made a comment early on like it made everything easier from marketing to fulfillment I think the marketing one's a little bit obvious um and you covered a little bit so can you hit on like maybe briefly on how did it change how you marketed and the benefit of that but then go kind of a little bit deeper into how did it really benefit you on the delivery side that maybe some other folks listening that can't wrap their head around why narrowing down like this is going to make the delivery easier or rather yeah on the marketing side I mean we just looked at it we're like okay well we branded our company around it so now we're sending this signal so if anyone hits our site they're either in or they're out right they're either our remodeler or Builder they're not but then we started just going down that chain we're like well we have a podcast well that's Builder funnel radio we have a YouTube That's Builder Channel TV and it's like all the content was just centered around that so you start getting found for that all the blog articles are talking about things specific to remodelers not just like how to increase Legion generically because now you're competing with all the big sites that are talking about lead gen for any industry and so the more narrow it was you actually got to stand out more in those little pockets and then on sales calls too like when you're talking to people now you have all this content you can reference this all hyper personalized to them and all your case studies are personalized to them so I think people are probably getting the sense of like how it impacts the marketing side the delivery side it's similar like oh this campaign like just went crazy for this one client over in Seattle like let's roll it out across everybody you know and so you can deliver you know that result but also if you have oh like gosh this campaign becomes a part of our standard first one or two months because it delivers quicker wins and we know it has a high probability of succeeding so that increases your odds of success with your clients because it's work for one has worked for a few and now you build it on early you get a quicker win you start to see results and so your lifetime value goes up but now people know how to execute those campaigns at a high level because they're running them all the time you know they're doing the same plays oh these blog topics are always great in all these different markets like let's front load those so you start to standardize delivery and then you can train to it and then the strategy piece is like that's where maybe the more experienced people are like building the strategy and that's more nuanced but then the execution becomes less nuanced I mean you can train and scale scale is overused but I mean you can train more people faster you know doing the same things instead of having everyone that needs all of this unique knowledge you know yes yeah how many people are on your team we're about 20 right now 20 nice and are you remote yep yeah yeah we were we were like half and half maybe five years ago and then yeah over the last couple years we've got maybe four people in Colorado Springs where headquarters is but yeah I mean nobody ever comes in except me where are you Colorado Springs did you know I'm in Denver what no I didn't know that yeah oh well we should have been yeah this morning yeah yeah that's funny yeah we'll have to hang out yeah that was crazy but yeah we're all remote because I'm the only one that comes into the office so yeah cool the other thing I wanted to kind of cover is inside of that blueprint it sounds like you offer a variety of things you covered like how they approach content blogging the social side you also I think I heard you say some SEO stuff but also paid so you kind of cover the full gamut of quote-unquote marketing which in this example I often don't mind when like people kind of combine a variety of these things to achieve a specific outcome it works a lot better when you are specialized into such a homogeneous market and I think that's where some people struggle and so like that's what I think you probably gravitated towards you know Alex's book I mean and a lot of people gravitated towards this book for a lot of reasons but like I think one thing that people don't pull out of this and maybe this is the path you're going but like with Builders being so homogeneous like that the example of the social content in canva that could like hey here it is just swap out an image sort of thing like that's content that could be licensed right like hey this campaign we know works like that's where you start licensing IEP for those that haven't watched my interview with Alex on our Channel you should check it out because the thing that he talks about often is like having a sticky component to the offering and in his case for the gyms like they were giving their gyms ad campaigns that they knew would work because they were working in you know their 20 test markets it was as little as swap about you know colors logo and images but like copy was all the same and because they worked with all of the same type of gym they could all use it and it would work for everybody which is what's great about what you're doing where as some of you guys listening you might not have the benefit of having such a homogeneous market and like some of those things might not be as Plug and Play Alex would probably suggest that we would aim to do that it's something we considered but we kind of like a little bit of the diversity it creates challenges for us for sure but you know choose your heart right at the end yeah yeah they all have challenging components like Grass Is Always Greener like they all have yeah difficult did you ever think like that as you kind of Incorporated all elements of marketing paid SEO content did you ever think of not like removing it and only doing one of those things was that ever even like an option on the table like hey we're just gonna focus on paid for remodelers it's funny we we didn't really consider that and as you were kind of talking about that was like I wonder why we didn't really look at just like yeah just doing paid or just doing SEO or something and I think it was because like we started and we early on partnered with HubSpot as a partner agency and so like we were pretty much drinking the Kool-Aid of like the full funnel approach like the holistic approach and yep and I think for our guys like that made a lot of sense because somebody might do a Google search today and they're thinking about their kitchen that they're not going to do for a year and it's like well we need to capture them so we need to have a lead conversion component we're thinking top of funnel and then we need to be like on social because if they're gonna then pop over to their social and follow them there for nine months and they're getting the emails and so I could just see that like long buying cycle long marketing cycle long sales cycle like we need to be kind of integrated a lot across a lot of channels and I think I just like I got it like it just makes sense to me like to have those components and it was like there's a framework there's a methodology I like that and so I didn't ever think to do that although I'm sure we could have picked a couple components just said we're gonna get hyper specialized here yeah I know I mean I'm glad you didn't and I think like the long-term benefit for you obviously is high LTV and you know multi-year retention you know because a lot of the it's not like a negative but like a lot of folks that we come across like they I want to say a one-dimensional skill but like they've only ever done paid ads for example we don't actually deal with a ton of Legion agencies so I'm not sure why I'm using that example but like they're really good at paid ads but like I think you Silo down to any one type of skill set or service there's always the risk of over time that's starting to feel like a commodity because you're just kind of pain it's almost like you pay someone to run your ads is very similar to in my opinion the feeling that one would get of like paying for web hosting right like it becomes very mechanical and it's like there's a certain amount of time you're like oh like we could bring this in-house you know for more affordable or you know not have to pay a percentage of AD spend or whatever agencies are doing these days but when you have like oh well like in phase one one we're focusing on this but then we can add on this and then we can add on this and the blueprint shows the sequence of you know which do you do in which order so that you don't kill yourself you start to see the future like the client can see the future of like oh yeah like we have all of these things left to do it's a conversation we have with our clients like how do you show them what's coming like you have to always be showing them the future and what the future can look like which helps with retention and so you having this whole blueprint I think helps as a one document like hey look like we can show you what we're going to be likely doing in you know six months from now assuming all of these things are working as fast so I think that's to your advantage as you started building this out you know something we hear a lot from agencies like what you do like if for anyone who's been listening it sounds like what you do is very Hands-On when you do the done for you like there's a lot of work there's a lot of things you're building and managing creating how did you navigate the transition into the making it so easy that they can do it because the common narrative in this environment is like well my client won't want to do it or they just won't do it but as we've kind of alluded to earlier there's a segment of the market both lower and higher that will be willing to do it so can you kind of talk through that like my client won't actually do this it's just easier for me to do it on their behalf mm-hmm yeah that's interesting to think about maybe we kind of I don't know lucked into it in a way but as we're building our old model of retainers like we were bringing in lots of like young marketers out of college and so we built really good training videos and Sops to train everyone as they're coming in and a lot of our people like they start as an intern or a specialist they build their way up you know that's our current president who runs all of operations like she started there too and like worked her way up and so when we built the blueprint we're like well gosh this is a lot of stuff if they're gonna do it like they need to have all the tools and so we kind of just like locked in that phrase like we need to have like a marketing intern be able to implement this and so you know every line item was like hey this is how you write a blog here's the training video on how to incorporate SEO and internal links and heading structure all the like Nuance detail and then there'd be like a doc that's the SOP so they had the video and the SOP to go with it but when we deliver the blueprint we give them like it's extreme detail it's this is the blog title it should be a thousand words this is the summary of the blog these are the questions you should answer in the blog this is the keyword research that's for one blog and we're usually given you know 24 36 articles a year that they're going to write two or three a month and so they have that and of course those are all fresh being generated like new we create that in the blueprint yeah like that's what's in here so if and that's why it's a one-year thing because we're giving them like these are the things to do this year and then next year it's going to be these are new titles but now these blogs we need to go back and historically optimize because 2022 is out of date so we're gonna go and update this we're going to beef it up we're going to use that equity in that old URL to get stronger you know so like there's nuance and layers like year over year and so when people renew like yeah maybe we don't need to do the market research again but we layer in like now there's automation now there's like video now there's you know there's new things to incorporate kind of like you said like you're going to layer in these things we just do it annually with the blueprint instead of like quarterly or every six months and and we do those check-ins just in case like hey this isn't working we need to make a pivot or something but generally I think people fail with marketing think about our clients because they aren't consistent for long enough and so getting people to think longer terms sign on to longer term things and just do it like do it for a year like you'll be a lot further along than you are have you had any clients be like or prospects hesitant on the your commitment it used to happen more but people don't really yeah they don't get hung up as much anymore and I'm trying to figure out why it's a good question I mean and I think part of it might be like everyone goes through the blueprint and when they get the blueprint I mean you go through that thing I mean it's literally really 130 to 150 pages of like all of our research and findings and then the plan for the next year and they're like holy cow like the year's laid out so it just makes sense that I would sign on for a year if they're going to do the done for you when you do the blueprint in the done with youth format are they just going through it or that's always done for you the blueprint yeah we always build blueprint Forum yeah and so they get okay they get the printed book they get the pdf version and then they get the Asana board that's basically a 12-month checklist of everything they need to do in every single month with the training videos the Sops all the details so they can literally log in like it's February here's my checklist and here's the how to do all those things right there just follow the chat what tool are you using to manage all that Asana so we just give a Max like we build the board and then give them access to it and they and that's part of what they get access to is the Asana board with all the links to the training and so that if they renew they just keep it but then we do a new board for them for the next year and then if they don't want to then they're not and they go on their way and maybe they learned enough so so unlike most agencies that I talk to it it sounds like you Market yourself actually do do marketing so can you talk a little bit about what are you guys currently doing to get clients what's working yeah I'll try to just break it down really quick so we do regular blogging on our site at this point we have three different podcasts that used to be just one we've been doing one for several years Builder funnel radio I do that one it's either marketing topics or I bring in guests we do remodeler stories this is a great topic for anyone thinking about a niche I literally find remodelers that would be my client bring them on to the show talk about their Journey as an entrepreneur as a remodeler for 30 minutes and then we promote them and so it's a great connection Builder like build people into the funnel so we do those two and then we have another one that our team does and that's more like you know case studies and real tactical stuff like stuff we're doing this week or this month you know real recent stuff and so we run two of those weekly remodeler Stories We oscillate between like one and three times a week because sometimes we just I mean it's easy to book those we do a YouTube channel so we do one video week educational we all only just do one trade show a year really and it's just it's hyper focused it's all of our target audience it's pretty small it's like two to four hundred people but it's like almost like 80 percent of it could be our client and then we'll do some like guest webinars and guests you know stuff like that for other coaches in the space you know that do sales coaching for remodelers and but it's a lot of the stuff that we do for our clients like content marketing is the core of what we do we do very little paid we're trying to figure that out but you know I don't know we're still working on it I love it one final question before like kind of parting words is um and if you don't have to share if you're not willing to but like percentage breakdown right now of like people taking the done for you versus the done with you versus the DIY like of the total revenue what percentage does it look like currently yeah the last time I ran it I'm pretty sure it was right around 75 percent do the full package they want us to do it and then I haven't broken it down to the DIY just think about the top twos I've brought 75 25 and then we just we you just pick up some people into the DIY and so far again we're pretty new into it but all of the original blueprints that we did that were self-implemented so the middle they're done with you they've all renewed for year two so we think that's a good good sign yeah so yeah we'll see how it plays out but yeah I thought it was interesting when we first launched it like last year the first three quarters were tough like Q4 we sold our first few and then it was like really slow our industry was Bonkers busy so they didn't care about marketing and so we didn't sell our first blueprint into implementation until like May or something and it was like man maybe everyone's just going to do the blueprint they don't actually want us to do so we like Turned some clients and we were hitting the Zone where it was like blueprints were kind of like bumping us up a little bit but then once the market kind of normalized I would say like remodeling is still in like a normalized phase they're just from two years ago like everything went nuts so yeah we I mean Q4 was bananas for us and q1's looking like we're booked out we're not kicking off blueprints until May because we're booked out that far and so that's the other thing we've done is just saying we only have X slots per month so when you get on a call it's added a little bit of urgency and I never try to pressure people it's just not my style I like I want people to make a big ticket decision not like it's the right thing for your business but it has like people are like oh that spot's gone now I can just email like that spot's gone now our next spot is in here and so people are kind of like getting the message so I feel like we're hitting this like momentum shift now after being into trying to sell something new trying to sell something that was much higher price at the beginning figuring out like the handoffs internally so yeah it's not going to happen overnight maybe well for some people but it didn't for us I mean it took us like kind of 11 months to like really have the done with you piece start to rival slash surpass the done for you piece which I would actually still say depending upon where you're at in your agency when you start this that's probably like an average like I mean I've had clients that were like more kind of on the they had fewer Legacy clients that they were dealing with and they made the switch like in 90 days which I'd say is extremely fast not common but like yeah you kind of got to look at like if the goal is to have this done with you saying then not everyone will replace and surpass done for you Revenue which I know some want you're looking at at least a year process you know depending upon you know what sort of baggage you're coming with yeah that's interesting I hadn't really like that wasn't really our goal I guess to replace the done for you but that's interestingly ours either it wasn't yeah like it's just accidentally kind of happened that way and then it got to the point where we were like well do we want to do done for you anymore yeah interesting and we chose not to but what I do think is actually interesting is that like we have conversations all the time of bringing a done for you layer back and so while I do think it does help with focus of like hey like look kind of like you said we're gonna start selling this and this being our Focus just with like the delivery vehicle where you're like hey like we want to really like further fine-tuned the done with you delivery piece let's lower the capacity of done for use Force the sale of the done with you get more experience there raise the price of the done for you possibly and like and then kind of come back and reintroduce it so I think there's seasons and that's the great thing there's just so many variations to how you can actually do this but nonetheless the three tiers is pretty powerful so dude thank you so much for reaching out for a random Builder a remodeler is watching a YouTube channel listening to the show check out builderfunnel.com you're obviously on social where else can people find you yeah honestly if you just want to connect with me linkedin's probably the best or just hit up our website and shoot me a message and get connected there yeah yeah thanks for having me on this was fun it's fun to talk to you yeah thanks for reaching out and we'll have to link up now that I know you're 40 minutes away yeah yeah for sure I hope you enjoyed the video with me and Spencer if you want to watch the same video that he watched around the three income streams that all agencies need to have that kind of sparked a lot of this conversation go click here and check it out\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "video_url = 'https://www.youtube.com/watch?v=yykGW30zgyE'\n",
    "transcript = get_transcript(video_url)\n",
    "video_info, video_title = my_utils.get_yt_video_info(video_url)\n",
    "\n",
    "\n",
    "formatter = TextFormatter()\n",
    "\n",
    "txt = formatter.format_transcript(transcript).replace(\"\\n\", \" \")\n",
    "txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from typing import List\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Questions\n",
       "\n",
       "- How did Spencer Powell from Builder Funnel transform his custom services agency into a specialized productized delivery structure for his clients?\n",
       "- What market selection process led Spencer to focus on serving remodeling companies and custom builders?\n",
       "- Why did Spencer find it challenging to specialize and focus on a specific industry within the builder and remodeler space?\n",
       "- How did Spencer make the decision to focus on remodelers and builders and what were the challenges he faced?\n",
       "- How did Spencer's background in working with his family's home building and remodeling business influence his decision to specialize in serving remodelers and custom builders?\n",
       "- What was the process behind Spencer's decision to create a blueprint offering for his clients and how did it transform his agency's delivery structure?\n",
       "- How did Spencer navigate the transition from offering full-service retainer packages to implementing the blueprint and done with you productized services?\n",
       "- What percentage breakdown does Spencer currently have for clients choosing the done for you, done with you, and DIY options in his agency?\n",
       "- How did Spencer incorporate various marketing strategies like blogging, podcasts, YouTube, and trade shows to attract clients to his agency?\n",
       "- What tools and strategies did Spencer use to manage the delivery of the blueprint and done with you services for his clients, ensuring ease of implementation and success?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You extract surprising, insightful, and interesting information from text content. You are interested in insights related to the purpose and meaning of life, human flourishing, the role of technology in the future of humanity, artificial intelligence and its affect on humans, memes, learning, reading, books, continuous improvement, and similar topics.\n",
    "\n",
    "Take a step back and think step-by-step about how to achieve the best possible results by following the steps below.\n",
    "\n",
    "STEPS\n",
    "1. Extract 5 to 15 of the most important, insightful, and/or interesting answered question in the input in a section called questions. If there are less than 15 then collect all of them. Make sure you extract at least 3.\n",
    "\n",
    "OUTPUT INSTRUCTIONS\n",
    "Only output Markdown.\n",
    "Extract at least 5 questions answered from the content.\n",
    "Do not give warnings or notes; only output the requested sections.\n",
    "You use bulleted lists for output, not numbered lists.\n",
    "Do not repeat questions.\n",
    "Ensure you follow ALL these instructions when creating your output.\n",
    "\n",
    "Input:\n",
    "{transcript}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "model_parser = model | StrOutputParser()\n",
    "\n",
    "chain = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"transcript\": txt})\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(chain.invoke({\"transcript\": txt})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Dict\n",
    "\n",
    "class Questions(BaseModel):\n",
    "    questions: Dict[str, str] = Field(\n",
    "        ..., \n",
    "        description=\"Dynamic dictionary to store an arbitrary number of questions.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Questions)\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    template = \"\"\"\n",
    "You extract surprising, insightful, and interesting information from text content. You are interested in insights related to the purpose and meaning of life, human flourishing, the role of technology in the future of humanity, artificial intelligence and its affect on humans, memes, learning, reading, books, continuous improvement, and similar topics.\n",
    "\n",
    "Take a step back and think step-by-step about how to achieve the best possible results by following the steps below.\n",
    "\n",
    "STEPS\n",
    "1. Extract up to 50 of the most important, insightful, and/or interesting answered question in the input in a section called questions. If there are less than 15 then collect all of them. Make sure you extract at least 3.\n",
    "\n",
    "OUTPUT INSTRUCTIONS\n",
    "{format_instructions}\n",
    "\n",
    "Input:\n",
    "{transcript}\n",
    "\"\"\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "model_parser = model | parser\n",
    "\n",
    "chain = prompt1 | model | parser\n",
    "\n",
    "output = chain.invoke({\"transcript\": txt})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': {'1': 'Where did the market selection for specializing in remodelers come from?',\n",
       "  '2': 'How did Spencer navigate the transition into making marketing easier for clients to implement?',\n",
       "  '3': 'What is the breakdown of clients taking the done for you, done with you, and DIY options at Builder Funnel?',\n",
       "  '4': 'What are some of the marketing strategies used by Builder Funnel to attract clients?',\n",
       "  '5': 'How did the Blueprint offering impact the marketing and delivery of services at Builder Funnel?'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where did the market selection for specializing in remodelers come from?\n",
      "How did Spencer navigate the transition into making marketing easier for clients to implement?\n",
      "What is the breakdown of clients taking the done for you, done with you, and DIY options at Builder Funnel?\n",
      "What are some of the marketing strategies used by Builder Funnel to attract clients?\n",
      "How did the Blueprint offering impact the marketing and delivery of services at Builder Funnel?\n"
     ]
    }
   ],
   "source": [
    "output\n",
    "import json\n",
    "json_string = json.dumps(output)\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "\n",
    "# Now you can access the data as a Python dictionary\n",
    "# For example, to print all questions:\n",
    "for key, question in json_object['questions'].items():\n",
    "    print(f\"{question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where did the market selection for specializing in remodelers come from?\n",
      "How did Spencer navigate the transition into making marketing easier for clients to implement?\n",
      "What is the breakdown of clients taking the done for you, done with you, and DIY options at Builder Funnel?\n",
      "What are some of the marketing strategies used by Builder Funnel to attract clients?\n",
      "How did the Blueprint offering impact the marketing and delivery of services at Builder Funnel?\n"
     ]
    }
   ],
   "source": [
    "outputs_list = []\n",
    "for question_number, question_text in output['questions'].items():\n",
    "    print(f\"{question_text}\")\n",
    "    prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Read the provided transcript and answer the provided question based on the information in the transcript. \n",
    "\n",
    "    Take a step back and think step-by-step about how to achieve the best possible results by following the steps below.\n",
    "\n",
    "    INPUT\n",
    "    {transcript}\n",
    "\n",
    "    Question \n",
    "    {question}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    chain2 = prompt2 | model | StrOutputParser()\n",
    "\n",
    "    output2 = chain2.invoke({\"transcript\": txt, \"question\": question_text})\n",
    "    video_title = my_utils.sanitize_title_for_display(video_title)\n",
    "    \n",
    "    # Save question and output as a pair in outputs_list\n",
    "    outputs_list.append((question_text, output2))\n",
    "    \n",
    "my_utils.save_to_unprocessed(outputs_list, video_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\vital\\\\iCloudDrive\\\\streamlit_suite\\\\src')\n",
    "from my_utils.my_utils import MyUtils\n",
    "\n",
    "my_utils = MyUtils()\n",
    "\n",
    "my_utils.save_to_unprocessed(output2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from IPython.display import Markdown, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='https://thedankoe.com/letters/zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day/', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[ ![Dan Koe\\nLogo](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20401%20311\\'%3E%3C/svg%3E)\\n![Dan Koe Logo](https://thedankoe.com/wp-content/uploads/2022/04/logo-\\nwhite.png) ](https://thedankoe.com)\\n\\n  * [Letters](https://thedankoe.com/letters/)\\n  * [Resources](/#resources)\\n  * [Work With Me](https://intake.kortex.co)\\n  * [About](/#about)\\n\\n____ Menu\\n\\n  * [Letters](https://thedankoe.com/letters/)\\n  * [Resources](/#resources)\\n  * [Work With Me](https://intake.kortex.co)\\n  * [About](/#about)\\n\\n__ Search\\n\\nSearch\\n\\n__ Close this search box.\\n\\nNot A Subscriber?\\n\\n**Join 140,000+ getting mindf*cked every Saturday morning** while reading The\\nKoe Letter (you\\'ll learn a bit about life & business too.)\\n\\nYour email\\n\\nRead For Free\\n\\n__\\n\\n__\\n\\n__\\n\\n__\\n\\n__\\n\\n#####\\n[Entrepreneurship](https://thedankoe.com/blog/category/entrepreneurship/)\\n\\n  * [ February 17, 2024 ](https://thedankoe.com/blog/2024/02/17/)\\n  * [ Dan Koe  ](https://thedankoe.com/blog/author/user6261b67bcb26b/)\\n\\n# Zero To $1 Million As A One-Person Business (While Working 2-4 Hours Per\\nDay)\\n\\nAnnouncement:\\n\\nThe Future Of Work event begins in 3 weeks.\\n\\nIf you want to start your one-person business, learn digital writing from\\nleading creators, and get beginner to advanced strategies [register\\nhere.](https://thefutureofwork.events)\\n\\n* * *\\n\\n_If you \\'ve solved a problem in your life, you\\'re qualified to start a\\nbusiness._\\n\\nNot just any business.\\n\\nAn education business.\\n\\nAs one person.\\n\\nWith close-to-zero startup costs.\\n\\nWith the knowledge you already have in your head (regardless of experience\\nlevel).\\n\\nMost people try to build a \"startup\" or some crazy idea they came up with\\nafter a night of drinking with their friends.\\n\\nThey think their idea will change the world, but they\\'re usually delusional\\nbecause they don\\'t have any prior business experience.\\n\\nIf you\\'ve had the idea with zero experience (meaning your mind can only have\\nso many good ideas… you haven\\'t built anything that leads to better ideas)\\nthen I can almost guarantee someone has already tried and failed with it.\\n\\nThere are special cases of course, but it\\'s better not to bank on luck here.\\n\\nThere\\'s a reason people are making millions solving fitness, productivity,\\ncareer, money, relationships, and lifestyle problems:\\n\\nBecause every person has them.\\n\\nBecause they prevent the average individual from doing the only thing they\\nwant… enjoying life.\\n\\nWhat better (and more profitable) problem is there to solve than one _you_\\nexperience every day?\\n\\n### Solve Your Own Problems & Sell The Solution\\n\\nIf you\\'ve gotten results in fitness, sell a fitness program.\\n\\nIf you\\'ve gotten results with focus, sell a productivity course.\\n\\nIf you\\'ve gotten results with a skill, sell a tutorial.\\n\\nThe list goes on.\\n\\n\"Dan, everyone is selling an information product nowadays… it seems like a\\nscam.\"\\n\\nAgain with the lack of perspective. You don\\'t have the experience that allows\\nyou to make sense of the industry.\\n\\nIt also shows that you don\\'t understand Business 101: sell what\\'s already\\nselling. Especially if you\\'re just starting out. Don\\'t chase blue oceans,\\nthere\\'s a reason money isn\\'t flowing there and you aren\\'t smarter than Mother\\nNature.\\n\\nThe school system is failing.\\n\\nEducation is the foundation of humanity.\\n\\nCreators are the decentralized school system.\\n\\nYou complain so much about how \"[insert any real-world problem here] should be\\ntaught in schools!\"\\n\\nNow that it is, at a fraction of the cost of formal education (if not free) on\\nthe internet, and can only be built out by a vast number of individuals who\\nsolve their own problems with direct experience… you call it a scam.\\n\\nThe only scam is you not taking responsibility for your future with the\\nplethora of information available to you outside of schools.\\n\\n### On Experience & Imposter Syndrome:\\n\\nPeople learn best from those who are similar to them.\\n\\nI used to think fat personal trainers were a silly concept, but I don\\'t think\\nthe average individual wants to be trained by a bodybuilder. They\\'d be\\ninsecure the whole time and can\\'t resonate with their identity.\\n\\nIn short: students will get _better_ results by learning from someone a few\\nsteps ahead of them.\\n\\nIt doesn\\'t matter if you aren\\'t a productivity guru with a billion-dollar\\ncompany.\\n\\nIt _does_ matter if you can focus for 2 hours and help someone who can only\\nfocus for 15 minutes.\\n\\nImposter syndrome is solved with honesty.\\n\\nYour marketing strategy should be solely based around where you are in your\\njourney and exactly what you help others with.\\n\\nThe industry has enough false and attention-grabbing promises.\\n\\n_In a market of extremes, if you want to be outstanding, all you have to do is\\nbe average._\\n\\n## Education Businesses Are The Future Of Schooling\\n\\n> We\\'re going to see 10 person billion dollar companies pretty soon. In my\\n> little group chat with my tech CEO friends, there\\'s this betting pool for\\n> the first year where there\\'s a 1 person billion dollar company. Which would\\n> have been unimaginable without AI. – Sam Altman\\n\\nYou don’t need statistics to observe reality.\\n\\nThe main pattern of reality is division and reunion.\\n\\nCentralization and decentralization.\\n\\nIn [The Art Of Focus](https://theartoffocusbook.com), I illustrate the\\nuncommon sense of the rain cycle. We all know it, but we often see it as a\\nsuperficial process of life rather than an indicator of life itself.\\n\\nThe ocean evaporates into divided droplets, reunifies in the clouds, divides\\ninto rain, and rain continues dividing and reuniting in plant life, our homes,\\nand more.\\n\\nThis happens in all dimensions and scales of reality.\\n\\nIn my prediction, backed by 4.5 billion years of evolution, the centralized\\nschool and economy are decentralizing thanks to the emergence of new\\ntechnology.\\n\\nThe internet, code, and now AI have allowed for the creator economy.\\n\\nComprised of one-person businesses educating, entertaining, and inspiring the\\nmasses (while making thousands to millions a year doing so).\\n\\nThe conventional education and employment path doesn’t make sense anymore.\\n\\nHumanity needs education, but not some idealized and regimented form that\\nantagonizes the wiring of our psyche and makes us hate learning – the one\\nthing that fuels all areas of your life.\\n\\nFrom corporation to individual (yes, public schools are corporations) reality\\nis decentralizing. Individuals who realize this can hop on one of the most\\nprofitable shifts in history.\\n\\n### The Massive Evolutionary Problem: Labor Work\\n\\n> The objective of work is usually to sustain our lives biologically, an\\n> objective we share with other animals. But the objective of leisure can and\\n> should be to sustain other aspects of our lives which make us uniquely\\n> human: our souls, our minds, our personal and civic relationships. Leisure\\n> is therefore wasted if we do not use it purposively. – Aristotle\\n\\nWork is a financial necessity.\\n\\nFinances are a necessity for survival.\\n\\nMoney is not to be demonized, but earned and used as a spiritual energy.\\n\\nWork and rest should not be seen as distinct opposites but complementary.\\n\\nCreative work is the future in a tech-enhanced society.\\n\\nEvolution is problem-solving to reverse entropy, and humans have been solving\\nproblems that make their life miserable since the dawn of time.\\n\\nWe want to avoid suffering, so we’ve built technology that allows us to do\\nwhat nature calls us to do: pursue personal development, expand our sense of\\nself, and do meaningful work that allows others to do the same.\\n\\n“We need more plumbers and construction workers!”\\n\\nI agree, but at some point, maybe in our lifetime, those jobs will not exist.\\n\\nShould everyone bank on creative work as the only path to meaningful work that\\ndoesn’t have an income cap? No. But smart people should.\\n\\nWith the advancements in robotics, and factories like Tesla being over 75%\\nautomated, I don’t see why robots can’t completely solve the problem that has\\nplagued humanity for a long time. It also doesn\\'t seem far off that we will\\nhave personal robots doing our laundry, cleaning our houses, and automating\\nlabor-intensive tasks so we can focus on creative work and self-actualization.\\n\\nYes, I\\'m sure some pleasure seekers will end up in VR headsets with Coca Cola\\nmainlined into their bloodstream, but wise people who flow with nature would\\nnever submit to that life. Success is reserved for the creative.\\n\\nYour psyche craves creativity. It feels good to create. By all measures,\\ncreating something of your own lights your brain on fire. That is enough of a\\nsign that humans are meant to do this.\\n\\nMy proposed way of life is using the internet as a creative extension of\\nyourself:\\n\\n  * Learn skills that can’t be taught in schools\\n  * Solve your own problems for personal evolution\\n  * Get results that can’t be achieved in employment\\n  * Put your personality on the internet to attract people like you\\n  * Help them solve their problems for collective evolution\\n  * Earn a meaningful independent income doing so\\n\\nThis is not another dogmatic business model, this is a way of life.\\n\\nTo become a vessel of creativity that solves problems (or removes limitations)\\nin your own life and others. Most people still see the internet as a shallow\\nplace to numb your mind when it is the digital world is the next stage of\\nconsciousness.\\n\\nI’ve written about this extensively in the past and break “how to do it” down\\nin [2-Hour Writer](https://2hourwriter.com) and, if you have a skill set and\\nvalue to provide – we help you even more over 16 weeks in [Kortex\\nUniversity](https://university.kortex.co).\\n\\nIn the context of this letter, you need to know how you can turn your skills\\nand interests into an education business:\\n\\n  * **Sell a tutorial (tutoring)** – Sell a beginner-level tutorial of a specific skill, practice, or interest. Web design, building cars, Photoshop, guitar.\\n  * **Sell a program (coaching)** – Sell an action plan or program that people can adopt as a daily routine. Fitness, productivity, self-improvement, etc.\\n  * **Sell a system (consulting or freelancing)** – Sell a system that people can implement into their work or business. Lead generation, content creation, etc.\\n\\nObserve the people who are doing what you want to do.\\n\\nReverse engineer how they are doing it. Buy their courses. Dissect their\\nfunnel. Study their content. Educate yourself along the way so you can\\nunderstand what they are actually doing.\\n\\n## Koe\\'s Law – Work Evolves To Earn More In Less Time\\n\\n![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%201024%201024\\'%3E%3C/svg%3E)\\n![](https://thedankoe.com/wp-content/uploads/2024/02/2-1024x1024.png)\\n\\n> **Koe \\'s Law:** _work evolves to earn more in the time allotted for its\\n> completion_. This demands creativity, growth, and skill acquisition to solve\\n> problems that prevent this evolution.\\n\\nWe\\'ve all heard of Parkinson\\'s Law.\\n\\nThat work expands to fill the time allotted for its completion.\\n\\nBut that\\'s only the first layer. Your work expands, but your income doesn\\'t.\\n\\nThe 4-hour workday has been my philosophy for quite some time.\\n\\nWhat people don\\'t realize is that with technology you can work that same\\namount of time while making as much money as you want.\\n\\nThe problem is that people get trapped in business ideologies.\\n\\nThey start as a freelancer, that\\'s all they know, they bias freelancing above\\nother models, and complain when they can\\'t escape the feast or famine cycle\\nwith just enough income to survive.\\n\\nBecause they identify as a freelancer, their mind can\\'t open beyond that to\\nperceive opportunities that allow them to better leverage their skill set.\\n\\nThey left the 9-5 to pursue freedom and created a new 9-5 for themselves.\\n\\nLet\\'s break down how Koe\\'s Law works in practical steps to evolve from $100K\\nper year to $100K per month.\\n\\n### Stage 1) Start With Client Work\\n\\nAs one person without an audience, client work is the best option.\\n\\nYou can use manual client acquisition strategies and charge between $1000 and\\n$10,000+ per client.\\n\\nYou only need 2-3 clients to replace your income.\\n\\nIn my eyes, it\\'s best to skip the freelancer stage and go straight to\\ncoaching, consulting, or tutoring as illustrated in the last section. Because\\neducation and teaching are pillars of the good life, it makes sense to\\nintegrate them in your work.\\n\\nYour time is allocated as such in a 4-hour time frame:\\n\\n  * 1 hour per day prospecting for new clients\\n  * 3-5 hours per week on sales calls\\n  * 2-4 hours per week on client calls\\n  * 1 hour per day writing content for audience and clients\\n  * The rest is filled with pour-over from any of these\\n\\nThe key is to hold the intention of evolution in your mind so you don\\'t get\\ntrapped in this stage.\\n\\n### Stage 2) Build An Audience & Evolve One Layer\\n\\nAs a client business, you can only take on so many clients with 4 hours of\\nwork.\\n\\nAnd if you want to stay as one person, you need to identify the route that\\nallows you to maintain that work time without hiring employees.\\n\\nI\\'ve discovered this route for you, so you don\\'t have to go through years of\\ntrial and error.\\n\\n  * **Build an audience with writing** – don\\'t waste time on video editing and graphics yet. Use [writing on social media and a newsletter](https://2hourwriter.com) to build an audience. If you need an example of this, just look at my Instagram, LinkedIn, and X.\\n  * **Use a new client model** – create a program, tutorials, or curriculum and take on more clients in a group coaching setting. This brings your client work down to 1-2 hours a week.\\n  * **Evolve your fulfillment** – decrease pricing a bit, remove time-suckers like 1 on 1 calls, introduce a group chat or community, and attempt to restructure how you deliver to your clients without removing any value.\\n\\nNow, thanks to Koe\\'s Law, you\\'ve increased your earning potential from $100K\\nper year to $300-$500K while working the same 4 hours.\\n\\n### Stage 3) Productize With Your Audience Growth\\n\\nDistribution = freedom.\\n\\nAudience = distribution.\\n\\nYou can turn your client work into a digital product at any time for extra\\nincome (and potentially more clients that needed to learn more before hiring\\nyou), but that won\\'t be your main source of income at first.\\n\\nIn this third stage, you:\\n\\n  * **Create a cohort-based program** – you charge less, restructure time-consuming aspects of your work, and take on more customers. Thanks to your larger audience, you earn more than a group client model while working the same amount of time.\\n  * **Build a standalone digital product** – use your teachings and results from your client work to build a successful product. You build it once and it sells while you sleep, adding to your income.\\n  * **Leave client work if you want** – you may see a dip in income at the start, but that newly allotted time is used to diversify platforms, increase revenue, and improve audience growth speed.\\n\\nAgain, thanks to Koe\\'s Law, you\\'ve increased your earning potential from $300K\\nper year to $1 million+ per year.\\n\\nThis is where rapid iteration comes into play. You must detach from manual\\nlabor and solely bank on your creative ability.\\n\\nYour time is allocated to:\\n\\n  * 1-2 hours per week fulfilling your cohort program\\n  * 2 hours per day writing content to fuel growth\\n  * 1-2 hours a day building projects that take you even further\\n\\nYou can build new products, branch out of the one-person business, or just\\nenjoy life for a bit until early retirement bores you enough to start\\nmeaningful building again.\\n\\nYou\\'ve built so much leverage and distribution that you can sell whatever you\\nwant.\\n\\nHire a team to build software.\\n\\nWork with a product developer to launch a physical product.\\n\\nWrite a book to solidify your legacy in the space.\\n\\nThen do it all over again because money is a tool to build what you want but\\ndoesn\\'t exist. Ignore anyone who tells you you don\\'t need to make more.\\n\\nMoney is energy, and we will discuss that more in the next letter.\\n\\n– Dan\\n\\nP.S. The Future Of Work event begins in 3 weeks.\\n\\nIf you want to start your one-person business, learn digital writing from\\nleading creators, and get beginner to advanced strategies [register\\nhere.](https://thefutureofwork.events)\\n\\n[__Prev PreviousHow I Unlock Insane Focus On Demand (The 4 Hour\\nFramework)](https://thedankoe.com/letters/my-1-million-productivity-framework-\\nthe-4-hour-workday/)\\n\\n[NextYou Are Obligated To Get Rich In Your 20s\\n__Next](https://thedankoe.com/letters/you-are-obligated-to-get-rich-in-\\nyour-20s/)\\n\\n__\\n\\n__\\n\\n__\\n\\n__\\n\\n__\\n\\n![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20800%20800\\'%3E%3C/svg%3E)\\n![](https://thedankoe.com/wp-content/uploads/2023/11/final4.jpg)\\n\\nWho Is Dan Koe?\\n\\nI am a writer & brand advisor for 7-8 figure creators, influencers, and social\\nmedia brands. **I am obsessed with dissecting human potential, lifestyle\\ndesign, and one-person businesses.**\\n\\nYou can work with my team to build your writing brand through my company,\\nKortex:\\n\\n[ Work With me ](https://intake.kortex.co)\\n\\nWhen You\\'re Ready, Here\\'s How I Can Help You:\\n\\n[\\n![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20768%20432\\'%3E%3C/svg%3E)\\n![](https://thedankoe.com/wp-content/uploads/2023/12/rectangle-768x432.jpg)\\n](https://thedankoe.com/planner)\\n\\nThe FOCI Planner\\n\\nGoals are important. If you want help reverse engineering your vision into\\nbite-size goals and tasks — **order The FOCI Planner.**\\n\\n[ Order Now ](https://thedankoe.com/planner)\\n\\n[\\n![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20768%20432\\'%3E%3C/svg%3E)\\n![](https://thedankoe.com/wp-content/uploads/2023/12/main-featured-\\nimage-768x432.jpg) ](https://theartoffocusbook.com)\\n\\nThe Art Of Focus Book\\n\\n**Find meaning, reinvent yourself, and create your ideal future.** Now\\navailable for preorder on Amazon.\\n\\n[ Get The Book ](https://theartoffocusbook.com)\\n\\n[ ![The 2 Hour\\nWriter](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20768%20432\\'%3E%3C/svg%3E)\\n![The 2 Hour Writer](https://thedankoe.com/wp-content/uploads/2022/08/cover-\\nimage-768x432.jpg) ](https://2hourwriter.com)\\n\\nThe 2 Hour Writer\\n\\n**Implement Our 2 Hour Content Ecosystem** To Learn High Impact Digital\\nWriting, Boost Your Online Authority, & Systemize Content Creation For Rapid\\nGrowth\\n\\n[ Enroll In 2HW ](https://2hourwriter.com)\\n\\n[\\n![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20768%20432\\'%3E%3C/svg%3E)\\n![](https://thedankoe.com/wp-content/uploads/2022/12/featured-\\nimage3-768x432.jpg) ](https://digitaleconomics.school)\\n\\nDigital Economics\\n\\nProductize yourself with my brand, content, marketing, and promotion systems.\\n**Everything you need to start, manage, and run a profitable one-person\\nbusiness.**\\n\\n[ Enroll Today ](https://digitaleconomics.school)\\n\\n![Dan Koe\\nLogo](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%20401%20311\\'%3E%3C/svg%3E)\\n![Dan Koe Logo](https://thedankoe.com/wp-content/uploads/2022/04/logo-\\nwhite.png)\\n\\nWork Less. Earn More. Enjoy Life.\\n\\nI dive deep into human potential, lifestyle design, and one-person businesses\\nto give you a unique, digestible way of improving your life.\\n\\n[ ](https://instagram.com/thedankoe) [ Twitter\\n__](https://twitter.com/thedankoe) [ Youtube\\n__](https://youtube.com/c/DanKoeTalks) [ Linkedin\\n__](https://linkedin.com/in/thedankoe)\\n\\nGain A New Perspective On Life & Business\\n\\n**Join 140,000+ subscribers getting mindf*cked while reading The Koe Letter**\\nevery Saturday morning (you may learn a bit about life & business too).\\n\\nYour email\\n\\nRead For Free\\n\\n© All Rights Reserved.\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://thedankoe.com/letters/zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day/\"]\n",
    ")\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.file import FlatReader\n",
    "from pathlib import Path\n",
    "parser = MarkdownNodeParser()\n",
    "md_docs = FlatReader().load_data(Path(\"C:\\\\Users\\\\vital\\\\iCloudDrive\\\\streamlit_suite\\\\src\\\\zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day.md\"))\n",
    "nodes = parser.get_nodes_from_documents(md_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'get_doc_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     md_docs \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     17\u001b[0m md_docs_split \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit_text(md_docs)\n\u001b[1;32m---> 18\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mSummaryIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmd_docs_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine()\n\u001b[0;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a summary on the future of work.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:133\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, service_context, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_construction\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m--> 133\u001b[0m         docstore\u001b[38;5;241m.\u001b[39mset_document_hash(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_doc_id\u001b[49m(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[0;32m    135\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[0;32m    136\u001b[0m         documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    137\u001b[0m         transformations,\n\u001b[0;32m    138\u001b[0m         show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    143\u001b[0m         nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    144\u001b[0m         storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    150\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Document' object has no attribute 'get_doc_id'"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter([\n",
    "    (\"# \", \"h1\"),\n",
    "    (\"## \", \"h2\"),\n",
    "    (\"### \", \"h3\"),\n",
    "    (\"#### \", \"h4\"),\n",
    "    (\"##### \", \"h5\"),\n",
    "    (\"###### \", \"h6\"),\n",
    "])\n",
    "\n",
    "parser = MarkdownNodeParser()\n",
    "md_docs = FlatReader().load_data(Path(\"C:\\\\Users\\\\vital\\\\iCloudDrive\\\\streamlit_suite\\\\src\\\\zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day.md\"))\n",
    "with open(\"C:\\\\Users\\\\vital\\\\iCloudDrive\\\\streamlit_suite\\\\src\\\\zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "    md_docs = file.read()\n",
    "\n",
    "md_docs_split = splitter.split_text(md_docs)\n",
    "index = SummaryIndex.from_documents(md_docs_split)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Write a summary on the future of work.\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The future of work is envisioned as a transition towards creative pursuits within a technologically advanced society. This shift emphasizes personal growth, problem-solving, and embracing creativity as essential elements for meaningful and fulfilling endeavors. Education businesses are emerging as decentralized alternatives to traditional schooling, offering accessible and cost-effective learning opportunities. Overcoming imposter syndrome through honesty and focusing on helping others is highlighted as a key to success in the evolving work landscape. Additionally, the concept of Koe's Law underscores the evolution of work towards earning more in less time, promoting creativity, skill acquisition, and continuous improvement. Building an audience, transitioning from client work to group coaching, and productizing services are identified as crucial steps in scaling one-person businesses to reach significant financial milestones."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://docs.llamaindex.ai/en/stable/understanding/querying/querying.html\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "index = VectorStoreIndex.from_documents(md_docs)\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Write a summary on the future of work.\")\n",
    "display(Markdown(f\"{response}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI \u001b[38;5;28;01mas\u001b[39;00m LIOpenAI\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m---> 37\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[43mmd_docs\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_sentence_window_index\u001b[39m(\n\u001b[0;32m     39\u001b[0m     documents,\n\u001b[0;32m     40\u001b[0m     llm,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m ):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# create the sentence window node parser w/ default settings\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     node_parser \u001b[38;5;241m=\u001b[39m SentenceWindowNodeParser\u001b[38;5;241m.\u001b[39mfrom_defaults(\n\u001b[0;32m     47\u001b[0m         window_size\u001b[38;5;241m=\u001b[39msentence_window_size,\n\u001b[0;32m     48\u001b[0m         window_metadata_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m         original_text_metadata_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'md_docs' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from trulens_eval import Tru\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import numpy as np\n",
    "from trulens_eval import (\n",
    "    Feedback,\n",
    "    TruLlama,\n",
    "    OpenAI\n",
    ")\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from llama_index.core import ServiceContext, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.llms.openai import OpenAI as LIOpenAI\n",
    "\n",
    "from llama_index.core  import Document\n",
    "document = md_docs\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "def build_sentence_window_index_nodes(\n",
    "    nodes,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex(\n",
    "            nodes, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_prebuilt_trulens_recorder(query_engine, app_id):\n",
    "    openai = OpenAI()\n",
    "\n",
    "    qa_relevance = (\n",
    "        Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "        .on_input_output()\n",
    "    )\n",
    "\n",
    "    qs_relevance = (\n",
    "        Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "        .on_input()\n",
    "        .on(TruLlama.select_source_nodes().node.text)\n",
    "        .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "    grounded = Groundedness(groundedness_provider=openai)\n",
    "\n",
    "    groundedness = (\n",
    "        Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "            .on(TruLlama.select_source_nodes().node.text)\n",
    "            .on_output()\n",
    "            .aggregate(grounded.grounded_statements_aggregator)\n",
    "    )\n",
    "\n",
    "    feedbacks = [qa_relevance, qs_relevance, groundedness]\n",
    "    tru_recorder = TruLlama(\n",
    "        query_engine,\n",
    "        app_id=app_id,\n",
    "        feedbacks=feedbacks\n",
    "    )\n",
    "    return tru_recorder\n",
    "\n",
    "\n",
    "\n",
    "def run_evals(eval_questions, tru_recorder, query_engine):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_14332\\2445352080.py:51: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_14332\\2445352080.py:51: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_14332\\2445352080.py:51: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "index = build_sentence_window_index(\n",
    "    md_docs,\n",
    "    llm=llm,\n",
    "    save_dir=\"./sentence_index\",\n",
    "    )\n",
    "\n",
    "eval_questions= [\n",
    "    \"How does the author justify the claim that starting a one-person business with minimal startup costs is feasible through solving a personal problem and creating an education business?\",\n",
    "    \"What evidence does the article provide to support the profitability of selling information products based on personal achievements in areas like fitness, focus, or skills?\",\n",
    "    \"In what ways does the author argue that education businesses represent the future of schooling and offer a decentralized alternative to traditional education models?\",\n",
    "    \"How does the author address overcoming imposter syndrome, and what strategies are suggested for individuals to be honest about their journey and expertise?\",\n",
    "    \"What arguments are made regarding the evolution of work towards more creative endeavors in a tech-enhanced society, and how is Koe's Law used to illustrate this shift?\",\n",
    "    \"Can you identify the steps recommended for building an audience and transitioning from client work to group coaching to increase earning potential?\",\n",
    "    \"How does productizing services and creating digital products contribute to income diversification and scalability, according to the article?\",\n",
    "    \"What role does rapid iteration and detachment from manual labor play in scaling a one-person business to achieve $1 million+ per year, as per the author's viewpoint?\",\n",
    "    \"What potential biases or weaknesses in the author's argumentation could affect the generalizability of the advice provided to a broader audience?\",\n",
    "    \"Considering the strengths and evidence presented, how compelling is the article's roadmap for aspiring entrepreneurs and freelancers looking to grow their one-person business?\"\n",
    "  ]\n",
    "\n",
    "\n",
    "#Tru().reset_database()\n",
    "    \n",
    "    \n",
    "sentence_index_1 = build_sentence_window_index(\n",
    "    md_docs,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1-koe-v2\",\n",
    ")\n",
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")\n",
    "\n",
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1-koe-v2'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)\n",
    "\n",
    "    \n",
    "    \n",
    "sentence_index_3 = build_sentence_window_index(\n",
    "    md_docs,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3-koe-v2\",\n",
    ")\n",
    "sentence_window_engine_3 = get_sentence_window_query_engine(\n",
    "    sentence_index_3\n",
    ")\n",
    "\n",
    "tru_recorder_3 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3,\n",
    "    app_id='sentence window engine 3-koe-v2'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)\n",
    "#Tru().run_dashboard()\n",
    "\n",
    "sentence_index_10 = build_sentence_window_index(\n",
    "    md_docs,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=10,\n",
    "    save_dir=\"sentence_index_10-koe-v2\",\n",
    ")\n",
    "sentence_window_engine_10 = get_sentence_window_query_engine(\n",
    "    sentence_index_10\n",
    ")\n",
    "\n",
    "tru_recorder_10 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_10,\n",
    "    app_id='sentence window engine 10-koe-v2'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_10, sentence_window_engine_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The future of work is envisioned as a transition towards creative pursuits within a technologically advanced society. This shift emphasizes personal growth, problem-solving, and embracing creativity as essential elements. Education businesses are seen as a decentralized alternative to traditional schooling, offering accessible and cost-effective learning opportunities. Overcoming imposter syndrome through honesty and focusing on helping others is highlighted as a key to success in the evolving work landscape. Koe's Law underscores the evolution of work towards earning more in less time, promoting creativity, skill acquisition, and continuous improvement. Strategies such as building an audience, transitioning to group coaching, and productizing services are emphasized as crucial steps in scaling one-person businesses for significant financial success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "index = VectorStoreIndex.from_documents(md_docs)\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Write a summary on the future of work.\")\n",
    "display(Markdown(f\"{response}\"))\n",
    "\n",
    "\n",
    "tru_recorder_VectorIndex = get_prebuilt_trulens_recorder(\n",
    "    query_engine,\n",
    "    app_id='VectorIndex_engine_topk10_simcutoff0.7'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_VectorIndex, query_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The future of work is envisioned as a transition towards creative pursuits within a technologically advanced society. This shift emphasizes personal growth, problem-solving, and embracing creativity as essential elements for meaningful and fulfilling endeavors. Education businesses are emerging as decentralized alternatives to traditional schooling, providing accessible and cost-effective learning opportunities. Overcoming imposter syndrome through honesty and focusing on helping others is highlighted as a pathway to success in the creator economy. Additionally, the concept of Koe's Law underscores the evolution of work towards earning more in less time, promoting creativity, skill acquisition, and continuous improvement. Strategies such as building an audience, transitioning from client work to group coaching, and productizing services are crucial steps in scaling one-person businesses towards achieving significant financial success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "index = VectorStoreIndex.from_documents(md_docs)\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Write a summary on the future of work.\")\n",
    "display(Markdown(f\"{response}\"))\n",
    "\n",
    "\n",
    "tru_recorder_VectorIndex = get_prebuilt_trulens_recorder(\n",
    "    query_engine,\n",
    "    app_id='VectorIndex_engine_topk5_simcutoff0.7'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_VectorIndex, query_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n",
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eec66a21fef42a0813c77cf34ed946b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.178.21:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tru().run_dashboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults(graph_store\u001b[38;5;241m=\u001b[39mgraph_store)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# NOTE: can take a while!\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mKnowledgeGraphIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_triplets_per_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[0;32m     21\u001b[0m     include_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a summary on the future of work.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:142\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, service_context, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[0;32m    135\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[0;32m    136\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     transformations,\n\u001b[0;32m    138\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    140\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\knowledge_graph\\base.py:99\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, llm, embed_model, storage_context, kg_triple_extract_template, max_triplets_per_chunk, include_embeddings, show_progress, max_object_length, kg_triplet_extract_fn, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m llm_from_settings_or_context(Settings, service_context)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m embed_model \u001b[38;5;129;01mor\u001b[39;00m embed_model_from_settings_or_context(\n\u001b[0;32m     96\u001b[0m     Settings, service_context\n\u001b[0;32m     97\u001b[0m )\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# TODO: legacy conversion - remove in next release\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_struct\u001b[38;5;241m.\u001b[39mtable) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_store, SimpleGraphStore)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_store\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mgraph_dict) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    114\u001b[0m ):\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:91\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 91\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:209\u001b[0m, in \u001b[0;36mBaseIndex.build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build the index from nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore\u001b[38;5;241m.\u001b[39madd_documents(nodes, allow_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\knowledge_graph\\base.py:205\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex._build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    201\u001b[0m nodes_with_progress \u001b[38;5;241m=\u001b[39m get_tqdm_iterable(\n\u001b[0;32m    202\u001b[0m     nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_progress, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes_with_progress:\n\u001b[1;32m--> 205\u001b[0m     triplets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_triplets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Extracted triplets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtriplets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m triplet \u001b[38;5;129;01min\u001b[39;00m triplets:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\knowledge_graph\\base.py:149\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex._extract_triplets\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kg_triplet_extract_fn(text)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm_extract_triplets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\knowledge_graph\\base.py:153\u001b[0m, in \u001b[0;36mKnowledgeGraphIndex._llm_extract_triplets\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_llm_extract_triplets\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract keywords from text.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkg_triple_extract_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_triplet_response(\n\u001b[0;32m    158\u001b[0m         response, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_object_length\n\u001b[0;32m    159\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\llms\\llm.py:253\u001b[0m, in \u001b[0;36mLLM.predict\u001b[1;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[0;32m    252\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m--> 253\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:93\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[1;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self) \u001b[38;5;28;01mas\u001b[39;00m callback_manager:\n\u001b[0;32m     85\u001b[0m     event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m     86\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m     87\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m         },\n\u001b[0;32m     92\u001b[0m     )\n\u001b[1;32m---> 93\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f_return_val, Generator):\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;66;03m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_gen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponseGen:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:237\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:296\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_client()\n\u001b[0;32m    295\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[1;32m--> 296\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m openai_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    302\u001b[0m message \u001b[38;5;241m=\u001b[39m from_openai_message(openai_message)\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\openai\\_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    915\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 918\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    924\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1295\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1168\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "# NOTE: can take a while!\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    md_docs,\n",
    "    max_triplets_per_chunk=2,\n",
    "    storage_context=storage_context,\n",
    ")\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    include_text=False, response_mode=\"tree_summarize\"\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Write a summary on the future of work.\",\n",
    ")\n",
    "display(Markdown(f\"{response}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = documents[0].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You extract surprising, insightful, and interesting information from text content. Identify the Main Ideas Of the Article.\n",
    "\n",
    "Take a step back and think step-by-step about how to achieve the best possible results by following the steps below.\n",
    "\n",
    "STEPS:\n",
    "1. Extract up to 15-50 of the most important, insightful, and/or interesting key points in a section called KEYPOINTS. If there are less than 15 then collect all of them. Make sure you extract at least 15.\n",
    "2. Extract up to 5-30 of the most important, insightful, and/or supporting arguments in a section called ARGUMENTS. If there are less than 5 then collect all of them. Make sure you extract at least 5.\n",
    "3. Extract up to 5-20 of the most important and/or insightful conclusions in a section called CONCLUSIONS. If there are less than 5 then collect all of them. Make sure you extract at least 5.\n",
    "\n",
    "OUTPUT INSTRUCTIONS\n",
    "- Only output Markdown.\n",
    "- Extract at least 15 KEYPOINTS answered from the content as Markdown H1 headers.\n",
    "- Extract at least 5 ARGUMENTS answered from the content as Markdown H1 headers.\n",
    "- Extract at least 5 KEYPOINTS answered from the content as Markdown H1 headers.\n",
    "- Do not give warnings or notes; only output the requested sections.\n",
    "- You use bulleted lists for output, not numbered lists.\n",
    "- Do not repeat key points, arguments or conclusions.\n",
    "- Ensure you follow ALL these instructions when creating your output.\n",
    "\n",
    "INPUT\n",
    "{article}\n",
    "\"\"\"\n",
    ")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "output = chain.invoke({\"article\": article})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "Tru().reset_database()\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.file import FlatReader\n",
    "from pathlib import Path\n",
    "parser = MarkdownNodeParser()\n",
    "md_docs = FlatReader().load_data(Path(\"C:\\\\Users\\\\vital\\\\iCloudDrive\\\\streamlit_suite\\\\src\\\\zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day.md\"))\n",
    "nodes = parser.get_nodes_from_documents(md_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_4268\\133356209.py:83: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict_messages` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_4268\\133356209.py:83: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_4268\\133356209.py:83: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "\n",
    "eval_questions= [\n",
    "    \"How does the author justify the claim that starting a one-person business with minimal startup costs is feasible through solving a personal problem and creating an education business?\",\n",
    "    \"What evidence does the article provide to support the profitability of selling information products based on personal achievements in areas like fitness, focus, or skills?\",\n",
    "    \"In what ways does the author argue that education businesses represent the future of schooling and offer a decentralized alternative to traditional education models?\",\n",
    "    \"How does the author address overcoming imposter syndrome, and what strategies are suggested for individuals to be honest about their journey and expertise?\",\n",
    "    \"What arguments are made regarding the evolution of work towards more creative endeavors in a tech-enhanced society, and how is Koe's Law used to illustrate this shift?\",\n",
    "    \"Can you identify the steps recommended for building an audience and transitioning from client work to group coaching to increase earning potential?\",\n",
    "    \"How does productizing services and creating digital products contribute to income diversification and scalability, according to the article?\",\n",
    "    \"What role does rapid iteration and detachment from manual labor play in scaling a one-person business to achieve $1 million+ per year, as per the author's viewpoint?\",\n",
    "    \"What potential biases or weaknesses in the author's argumentation could affect the generalizability of the advice provided to a broader audience?\",\n",
    "    \"Considering the strengths and evidence presented, how compelling is the article's roadmap for aspiring entrepreneurs and freelancers looking to grow their one-person business?\"\n",
    "  ]\n",
    "\n",
    "\n",
    "#Tru().reset_database()\n",
    "    \n",
    "    \n",
    "sentence_index_1 = build_sentence_window_index_nodes(\n",
    "    nodes,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1-koe-v3_node\",\n",
    ")\n",
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")\n",
    "\n",
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1-koe-v3_node'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)\n",
    "\n",
    "    \n",
    "    \n",
    "sentence_index_3 = build_sentence_window_index_nodes(\n",
    "    nodes,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3-koe-v3_node\",\n",
    ")\n",
    "sentence_window_engine_3 = get_sentence_window_query_engine(\n",
    "    sentence_index_3\n",
    ")\n",
    "\n",
    "tru_recorder_3 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3,\n",
    "    app_id='sentence window engine 3-koe-v3_node'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)\n",
    "#Tru().run_dashboard()\n",
    "\n",
    "sentence_index_10 = build_sentence_window_index_nodes(\n",
    "    nodes,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=10,\n",
    "    save_dir=\"sentence_index_10-koe-v3_node\",\n",
    ")\n",
    "sentence_window_engine_10 = get_sentence_window_query_engine(\n",
    "    sentence_index_10\n",
    ")\n",
    "\n",
    "tru_recorder_10 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_10,\n",
    "    app_id='sentence window engine 10-koe-v3_node'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_10, sentence_window_engine_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The future of work is evolving towards creative endeavors in a tech-enhanced society, emphasizing personal growth, problem-solving, and embracing continuous improvement. Education businesses are emerging as decentralized alternatives to traditional schooling, offering accessible and cost-effective learning opportunities. Overcoming imposter syndrome through honesty and focusing on helping others can lead to successful ventures in the creator economy. The concept of evolving work to earn more in less time promotes creativity, skill acquisition, and problem-solving. Building an audience, transitioning from client work to group coaching, and productizing services are key steps in scaling a one-person business to reach significant financial success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation error: 1 validation error for Rating\n",
      "rating\n",
      "  Value error, Rating must be between 0 and 10 [type=value_error, input_value=67, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.6/v/value_error\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from trulens_eval import (\n",
    "    Feedback,\n",
    "    TruLlama,\n",
    "    OpenAI\n",
    ")\n",
    "\n",
    "new_index_kg = KnowledgeGraphIndex(\n",
    "    nodes,\n",
    "    max_triplets_per_chunk=2,\n",
    "    include_embeddings=True,\n",
    ")\n",
    "# query using top 3 triplets plus keywords (duplicate triplets are removed)\n",
    "query_engine_kg = new_index_kg.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "response = query_engine_kg.query(\n",
    "    \"Write a summary on the future of work.\",\n",
    ")\n",
    "display(Markdown(f\"{response}\"))\n",
    "\n",
    "tru_recorder_11 = get_prebuilt_trulens_recorder(\n",
    "    query_engine_kg,\n",
    "    app_id='knowledgegraph-koe-v3_node'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_11, query_engine_kg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Empty Response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.file import FlatReader\n",
    "from pathlib import Path\n",
    "parser = MarkdownNodeParser()\n",
    "md_docs = FlatReader().load_data(Path(\"C:\\\\Users\\\\vital\\\\iCloudDrive\\\\streamlit_suite\\\\src\\\\zero-to-1-million-as-a-one-person-business-while-working-2-4-hours-per-day.md\"))\n",
    "nodes = parser.get_nodes_from_documents(md_docs)\n",
    "\n",
    "\n",
    "\n",
    "#https://docs.llamaindex.ai/en/stable/understanding/querying/querying.html\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "index10 = VectorStoreIndex(nodes)\n",
    "\n",
    "retriever10 = VectorIndexRetriever(\n",
    "    index=index10,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine_vectorindex10 = RetrieverQueryEngine(\n",
    "    retriever=retriever10,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "response = query_engine_vectorindex10.query(\"Write a summary on the future of work.\")\n",
    "display(Markdown(f\"{response}\"))\n",
    "\n",
    "\n",
    "tru_recorder_13 = get_prebuilt_trulens_recorder(\n",
    "    query_engine_vectorindex10,\n",
    "    app_id='vectorstore-koe-v3_node-sim10-cutoff0.7'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_13, query_engine_vectorindex10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The future of work is evolving towards creative pursuits within a technology-driven society, emphasizing personal development and problem-solving skills. Education businesses are emerging as decentralized alternatives to traditional schooling, offering accessible and cost-effective learning opportunities. Overcoming imposter syndrome through honesty and focusing on assisting others can lead to success in the creator economy. Work is transitioning towards earning more in less time, promoting creativity, skill acquisition, and problem-solving. Key steps in scaling a one-person business to exceed $1 million annually include building an audience, transitioning from client work to group coaching, and productizing services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "index5 = VectorStoreIndex(nodes)\n",
    "\n",
    "retriever5 = VectorIndexRetriever(\n",
    "    index=index5,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine_vectorindex5 = RetrieverQueryEngine(\n",
    "    retriever=retriever5,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "response = query_engine_vectorindex5.query(\"Write a summary on the future of work.\")\n",
    "display(Markdown(f\"{response}\"))\n",
    "\n",
    "\n",
    "tru_recorder_14 = get_prebuilt_trulens_recorder(\n",
    "    query_engine_vectorindex5,\n",
    "    app_id='vectorstore-koe-v3_node-sim5-cutoff0.7'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_14, query_engine_vectorindex5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
