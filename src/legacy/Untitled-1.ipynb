{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"C:\\\\Users\\\\vital\\\\iCloudDrive\\\\iCloud~md~obsidian\\\\new_vault\\\\\"\n",
    "\n",
    "\n",
    "documents = ObsidianReader(\n",
    "    BASE_PATH\n",
    ").load_data()  # Returns list of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "558 \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "Doc ID: 1b961cac-79bd-4ee2-8733-8af60844aa0a\n",
      "Text: References [[(MOC) How to get rich]]\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core  import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SyncHttpxClientWrapper.__del__ at 0x000002167E3EBEC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 714, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1264, in close\n",
      "    def close(self) -> None:\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents\n",
    ")  # Initialize index with documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_13688\\855792854.py:6: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import ServiceContext\n",
    "from llama_index.llms.openai import OpenAI as LIOpenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To structure a writing routine effectively, you should consider the following steps:\\n\\n1. **Set Clear Goals**: Define what you aim to achieve with your writing routine, whether it's to improve your skills, share knowledge, or build a portfolio.\\n\\n2. **Establish a Schedule**: Allocate specific time slots for writing in your daily or weekly calendar to ensure consistency and productivity.\\n\\n3. **Create a Dedicated Workspace**: Designate a comfortable and inspiring area where you can focus solely on your writing tasks.\\n\\n4. **Plan Your Topics**: Outline the subjects or themes you want to cover in your writing to maintain a sense of direction and purpose.\\n\\n5. **Practice Active Summarization**: Summarize key insights from your readings in your own words to enhance comprehension and retention.\\n\\n6. **Implement Tagging and Categorization**: Organize your notes and ideas using tags or categories to facilitate easy retrieval and connection of information.\\n\\n7. **Schedule Review Sessions**: Periodically review your notes to refresh your memory and identify new connections or insights that can enhance your writing.\\n\\n8. **Utilize the Zettelkasten Method**: Create a network of linked notes to organically grow your knowledge base and improve the accessibility of your information.\\n\\n9. **Share and Discuss**: Engage with a community or network to gain diverse perspectives, refine your thoughts, and explore new areas of interest related to your writing.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine(k=10)\n",
    "res = query_engine.query(\"How to structure a writing routine?\")\n",
    "res.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import ServiceContext, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_13688\\678983494.py:22: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "index = build_sentence_window_index(\n",
    "    [document],\n",
    "    llm=llm,\n",
    "    save_dir=\"./sentence_index\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_sentence_window_query_engine(index, similarity_top_k=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens_eval import (\n",
    "    Feedback,\n",
    "    TruLlama,\n",
    "    OpenAI\n",
    ")\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "def get_prebuilt_trulens_recorder(query_engine, app_id):\n",
    "    openai = OpenAI()\n",
    "\n",
    "    qa_relevance = (\n",
    "        Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "        .on_input_output()\n",
    "    )\n",
    "\n",
    "    qs_relevance = (\n",
    "        Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "        .on_input()\n",
    "        .on(TruLlama.select_source_nodes().node.text)\n",
    "        .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "    grounded = Groundedness(groundedness_provider=openai)\n",
    "\n",
    "    groundedness = (\n",
    "        Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "            .on(TruLlama.select_source_nodes().node.text)\n",
    "            .on_output()\n",
    "            .aggregate(grounded.grounded_statements_aggregator)\n",
    "    )\n",
    "\n",
    "    feedbacks = [qa_relevance, qs_relevance, groundedness]\n",
    "    tru_recorder = TruLlama(\n",
    "        query_engine,\n",
    "        app_id=app_id,\n",
    "        feedbacks=feedbacks\n",
    "    )\n",
    "    return tru_recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What are the most effective strategies for building long-term wealth?\",\n",
    "    \"How does investment diversification contribute to wealth accumulation?\",\n",
    "    \"Can you explain the importance of compound interest in wealth building?\",\n",
    "    \"What role does entrepreneurship play in achieving financial independence?\",\n",
    "    \"How crucial is financial literacy in the process of getting rich?\",\n",
    "    \"Describe the risks and benefits of real estate investment as a wealth-building strategy.\",\n",
    "    \"How can one balance risk and reward in stock market investments?\",\n",
    "    \"What are common financial mistakes people should avoid when trying to get rich?\",\n",
    "    \"How can setting financial goals contribute to wealth accumulation?\",\n",
    "    \"Explain the impact of personal savings rate on the path to becoming rich.\",\n",
    "    \"What are the key elements of a compelling narrative?\",\n",
    "    \"How can a writer effectively develop characters in a story?\",\n",
    "    \"Describe the process of outlining a story before writing.\",\n",
    "    \"How important is the setting in a story, and how can it be effectively described?\",\n",
    "    \"What techniques can writers use to maintain reader interest throughout a piece?\",\n",
    "    \"Discuss the role of conflict in storytelling and how it can be used effectively.\",\n",
    "    \"What are some common pitfalls in writing dialogue, and how can they be avoided?\",\n",
    "    \"How can writers improve their writing style and voice?\",\n",
    "    \"Explain the revision process and its importance in writing.\",\n",
    "    \"How can feedback from others be incorporated into the writing process?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "def run_evals(eval_questions, tru_recorder, query_engine):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:alembic.runtime.migration:Running upgrade  -> 1, first revision\n",
      "Running upgrade  -> 1, first revision\n",
      "Running upgrade  -> 1, first revision\n",
      "INFO:trulens_eval.database.sqlalchemy_db:Your database does not need migration.\n",
      "Your database does not need migration.\n",
      "Your database does not need migration.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_13688\\678983494.py:22: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "sentence_index_1 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ added app sentence window engine 1\n",
      "✅ added app sentence window engine 1\n",
      "✅ added app sentence window engine 1\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ added feedback definition feedback_definition_hash_8ce11fa811113b954233693dc9a04bc3\n",
      "✅ added feedback definition feedback_definition_hash_8ce11fa811113b954233693dc9a04bc3\n",
      "✅ added feedback definition feedback_definition_hash_8ce11fa811113b954233693dc9a04bc3\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ added feedback definition feedback_definition_hash_c2966bede85669c09973cb26a48b2244\n",
      "✅ added feedback definition feedback_definition_hash_c2966bede85669c09973cb26a48b2244\n",
      "✅ added feedback definition feedback_definition_hash_c2966bede85669c09973cb26a48b2244\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ added feedback definition feedback_definition_hash_1ecf412d1dd156ffdd5638284a33511d\n",
      "✅ added feedback definition feedback_definition_hash_1ecf412d1dd156ffdd5638284a33511d\n",
      "✅ added feedback definition feedback_definition_hash_1ecf412d1dd156ffdd5638284a33511d\n"
     ]
    }
   ],
   "source": [
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ added record record_hash_0b83030a7deaabc3cc6a22085240a368\n",
      "✅ added record record_hash_0b83030a7deaabc3cc6a22085240a368\n",
      "✅ added record record_hash_0b83030a7deaabc3cc6a22085240a368\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ feedback result Answer Relevance DONE feedback_result_hash_06c8b86106658fc86d23999d2e01e402\n",
      "✅ feedback result Answer Relevance DONE feedback_result_hash_06c8b86106658fc86d23999d2e01e402\n",
      "✅ feedback result Answer Relevance DONE feedback_result_hash_06c8b86106658fc86d23999d2e01e402\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ feedback result Groundedness DONE feedback_result_hash_d095d871995c860006cc4c749567df90\n",
      "✅ feedback result Groundedness DONE feedback_result_hash_d095d871995c860006cc4c749567df90\n",
      "✅ feedback result Groundedness DONE feedback_result_hash_d095d871995c860006cc4c749567df90\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ feedback result Context Relevance DONE feedback_result_hash_5a90d0c919e7c87d83d7229085266842\n",
      "✅ feedback result Context Relevance DONE feedback_result_hash_5a90d0c919e7c87d83d7229085266842\n",
      "✅ feedback result Context Relevance DONE feedback_result_hash_5a90d0c919e7c87d83d7229085266842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ added record record_hash_6319ea84d539780284708ef7e18cfe86\n",
      "✅ added record record_hash_6319ea84d539780284708ef7e18cfe86\n",
      "✅ added record record_hash_6319ea84d539780284708ef7e18cfe86\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "\nipython,ipywidgets packages are required for using trulens_eval in a notebook.\nYou should be able to install them with pip:\n\n    ```bash\n    pip install \"ipython>=8.12.0\" \"ipywidgets>=8.0.6\"\n    ```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mTru\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_dashboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\trulens_eval\\tru.py:990\u001b[0m, in \u001b[0;36mTru.run_dashboard\u001b[1;34m(self, port, address, force, _dev)\u001b[0m\n\u001b[0;32m    988\u001b[0m tunnel_started \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m notebook_utils\u001b[38;5;241m.\u001b[39mis_notebook():\n\u001b[1;32m--> 990\u001b[0m     out_stdout, out_stderr \u001b[38;5;241m=\u001b[39m \u001b[43mnotebook_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_widget_stdout_stderr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    992\u001b[0m     out_stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\trulens_eval\\utils\\notebook_utils.py:25\u001b[0m, in \u001b[0;36msetup_widget_stdout_stderr\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_widget_stdout_stderr\u001b[39m():\n\u001b[1;32m---> 25\u001b[0m     out_stdout \u001b[38;5;241m=\u001b[39m \u001b[43mwidgets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOutput\u001b[49m()\n\u001b[0;32m     26\u001b[0m     out_stderr \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mOutput()\n\u001b[0;32m     28\u001b[0m     acc \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mAccordion(\n\u001b[0;32m     29\u001b[0m         children\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     30\u001b[0m             widgets\u001b[38;5;241m.\u001b[39mVBox(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mopen\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Users\\vital\\streamlit_suite\\.venv\\Lib\\site-packages\\trulens_eval\\utils\\imports.py:361\u001b[0m, in \u001b[0;36mDummy.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dummy(\n\u001b[0;32m    354\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name,\n\u001b[0;32m    355\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    356\u001b[0m         importer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimporter\n\u001b[0;32m    357\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# If we are no longer in optional imports context or context said to\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# fail anyway, raise the exception with the optional package message.\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: \nipython,ipywidgets packages are required for using trulens_eval in a notebook.\nYou should be able to install them with pip:\n\n    ```bash\n    pip install \"ipython>=8.12.0\" \"ipywidgets>=8.0.6\"\n    ```\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ feedback result Answer Relevance DONE feedback_result_hash_ed0c6bdd7cbe699656ca7a7ad4903136\n",
      "✅ feedback result Answer Relevance DONE feedback_result_hash_ed0c6bdd7cbe699656ca7a7ad4903136\n",
      "✅ feedback result Answer Relevance DONE feedback_result_hash_ed0c6bdd7cbe699656ca7a7ad4903136\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ feedback result Context Relevance DONE feedback_result_hash_cd287beee42145abdd908c79b4d83289\n",
      "✅ feedback result Context Relevance DONE feedback_result_hash_cd287beee42145abdd908c79b4d83289\n",
      "✅ feedback result Context Relevance DONE feedback_result_hash_cd287beee42145abdd908c79b4d83289\n",
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "Will assume non-transactional DDL.\n",
      "INFO:trulens_eval.database.sqlalchemy_db:✅ feedback result Groundedness DONE feedback_result_hash_f4ad60f0b63448ba4a52207da6c494db\n",
      "✅ feedback result Groundedness DONE feedback_result_hash_f4ad60f0b63448ba4a52207da6c494db\n",
      "✅ feedback result Groundedness DONE feedback_result_hash_f4ad60f0b63448ba4a52207da6c494db\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)\n",
    "Tru().run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_3 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3\",\n",
    ")\n",
    "sentence_window_engine_3 = get_sentence_window_query_engine(\n",
    "    sentence_index_3\n",
    ")\n",
    "\n",
    "tru_recorder_3 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3,\n",
    "    app_id='sentence window engine 3'\n",
    ")\n",
    "run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)\n",
    "Tru().run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
